{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c802aa0e-a6f1-47ae-a493-9db03452021e",
   "metadata": {},
   "source": [
    "# Single perturbations\n",
    "\n",
    "In this notebook, we explore the effects of dual-node perturbations on the behaviour of the in vivo model.\n",
    "\n",
    "Specifically, we:\n",
    " 1. Build the petri net encoding of the model.\n",
    " 2. Generate knockouts for all druggable intervention combinations.\n",
    " 3. Filter out non-viable interventions (`Apoptosis >= 3` in `healthy` model)\n",
    " 3. Test remaining interventions on `mixed-myc-high` and `mixed-myc-low` models.\n",
    " 4. Compute and compare \"reliability\" and \"opportunity\" scores.\n",
    " 5. Compare distribution of opportunity and reliability scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f6b0b45-da80-4a3c-b28a-175e7de5fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trapmvn.core import trapmvn\n",
    "from trapmvn.representation.bma import BMA_Model\n",
    "from trapmvn.representation.symbolic import Symbolic_Model\n",
    "from trapmvn.representation.petri_net import Petri_Net\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "MODEL_TYPE = [\"healthy\", \"myc-low\", \"mixed-myc-low\", \"mixed-myc-high\", \"myc-high\"]\n",
    "\n",
    "DRUGGABLE_PROLIFERATION = Path(\"druggable.proliferation.txt\").read_text().split(\",\")\n",
    "DRUGGABLE_APOPTOSIS = Path(\"druggable.apoptosis.txt\").read_text().split(\",\")\n",
    "\n",
    "# These lists should be equivalent, they are just ordered differently\n",
    "# to mirror the result from the original paper.\n",
    "assert set(DRUGGABLE_APOPTOSIS) == set(DRUGGABLE_PROLIFERATION)\n",
    "DRUGGABLE = sorted(DRUGGABLE_APOPTOSIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cff1ee6-d3f0-45c0-b659-be3855480771",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for model_type in MODEL_TYPE:\n",
    "    models[model_type] = BMA_Model.from_json_file(f\"./models/in_vivo.{model_type}.json\")\n",
    "    \n",
    "variables = sorted(next(iter(models.values())).variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb8beff-ed00-487d-abe6-e6dc35d5464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated healthy.\n",
      "Translated myc-low.\n",
      "Translated mixed-myc-low.\n",
      "Translated mixed-myc-high.\n",
      "Translated myc-high.\n"
     ]
    }
   ],
   "source": [
    "petri_nets = {}\n",
    "\n",
    "# This should take a few seconds, since the models aren't exactly small.\n",
    "for model_type, model in models.items():\n",
    "    symbolic_model = Symbolic_Model.from_bma(model)\n",
    "    petri_nets[model_type] = Petri_Net.build(symbolic_model, unitary=True)\n",
    "    print(f\"Translated {model_type}.\")\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d70e3-af37-483a-9599-8e30dafbf721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ... 1/50; 2/50; A1_id357+ARF_id177.\n",
      "Computing ... 1/50; 3/50; A1_id357+Akt_id40.\n",
      "Skipped as non-viable.\n",
      "Computing ... 1/50; 4/50; A1_id357+BAD_id324.\n",
      "Computing ... 1/50; 5/50; A1_id357+BAXBAK_id318.\n",
      "Computing ... 1/50; 6/50; A1_id357+BIM_id323.\n",
      "Computing ... 1/50; 7/50; A1_id357+Bcl_2_id319.\n",
      "Computing ... 1/50; 8/50; A1_id357+Bcl_W_id356.\n",
      "Computing ... 1/50; 9/50; A1_id357+Bcl_xl_id320.\n",
      "Computing ... 1/50; 10/50; A1_id357+Beta_Catenin_id227.\n",
      "Computing ... 1/50; 11/50; A1_id357+CDK2_id644.\n",
      "Computing ... 1/50; 12/50; A1_id357+CDK4_id60.\n",
      "Computing ... 1/50; 13/50; A1_id357+COX2_id564.\n",
      "Computing ... 1/50; 15/50; A1_id357+Caspase9_id343.\n",
      "Computing ... 1/50; 16/50; A1_id357+E2F_1_id199.\n",
      "Computing ... 1/50; 17/50; A1_id357+EP4_id610.\n",
      "Computing ... 1/50; 18/50; A1_id357+EZH2_id535.\n",
      "Computing ... 1/50; 19/50; A1_id357+Elk_1_id661.\n",
      "Computing ... 1/50; 20/50; A1_id357+ErbB1_id298.\n",
      "Computing ... 1/50; 21/50; A1_id357+Erk_id36.\n",
      "Computing ... 1/50; 22/50; A1_id357+Ets_2_id38.\n",
      "Computing ... 1/50; 23/50; A1_id357+Frizzled_id218.\n",
      "Computing ... 1/50; 24/50; A1_id357+GSK3_id45.\n",
      "Computing ... 1/50; 25/50; A1_id357+HIF1_id558.\n",
      "Computing ... 1/50; 26/50; A1_id357+Mcl1_id321.\n",
      "Skipped as non-viable.\n",
      "Computing ... 1/50; 27/50; A1_id357+Mek_id35.\n",
      "Computing ... 1/50; 28/50; A1_id357+Myc_id2.\n",
      "Computing ... 1/50; 29/50; A1_id357+Noxa_id325.\n",
      "Computing ... 1/50; 30/50; A1_id357+PEA3_id563.\n",
      "Computing ... 1/50; 31/50; A1_id357+PHD2_id557.\n",
      "Skipped as non-viable.\n",
      "Computing ... 1/50; 32/50; A1_id357+PI3K_id33.\n",
      "Skipped as non-viable.\n",
      "Computing ... 1/50; 33/50; A1_id357+PTEN_id531.\n",
      "Computing ... 1/50; 34/50; A1_id357+Raf_1_id34.\n",
      "Computing ... 1/50; 35/50; A1_id357+Ras_id32.\n",
      "Computing ... 1/50; 36/50; A1_id357+Rsk_id53.\n",
      "Computing ... 1/50; 37/50; A1_id357+TGFBeta_id9.\n",
      "Computing ... 1/50; 38/50; A1_id357+TGFR_id8.\n",
      "Computing ... 1/50; 39/50; A1_id357+TRAP1_id20.\n",
      "Computing ... 1/50; 40/50; A1_id357+VEGF_id671.\n",
      "Computing ... 1/50; 41/50; A1_id357+VHL_id556.\n",
      "Skipped as non-viable.\n",
      "Computing ... 1/50; 42/50; A1_id357+cFos_id662.\n",
      "Computing ... 1/50; 43/50; A1_id357+mdm2_id176.\n",
      "Skipped as non-viable.\n",
      "Computing ... 1/50; 44/50; A1_id357+p15_id22.\n",
      "Computing ... 1/50; 45/50; A1_id357+p16_id61.\n",
      "Computing ... 1/50; 46/50; A1_id357+p21_id19.\n",
      "Computing ... 1/50; 47/50; A1_id357+p27_id62.\n",
      "Computing ... 1/50; 48/50; A1_id357+p38_id617.\n",
      "Computing ... 1/50; 49/50; A1_id357+p53_id175.\n",
      "Computing ... 1/50; 50/50; A1_id357+pRb_id198.\n",
      "Skipped as non-viable.\n",
      "Computing ... 2/50; 3/50; ARF_id177+Akt_id40.\n",
      "Computing ... 2/50; 4/50; ARF_id177+BAD_id324.\n",
      "Computing ... 2/50; 5/50; ARF_id177+BAXBAK_id318.\n",
      "Computing ... 2/50; 6/50; ARF_id177+BIM_id323.\n",
      "Computing ... 2/50; 7/50; ARF_id177+Bcl_2_id319.\n",
      "Computing ... 2/50; 8/50; ARF_id177+Bcl_W_id356.\n",
      "Computing ... 2/50; 9/50; ARF_id177+Bcl_xl_id320.\n",
      "Computing ... 2/50; 10/50; ARF_id177+Beta_Catenin_id227.\n",
      "Computing ... 2/50; 11/50; ARF_id177+CDK2_id644.\n",
      "Computing ... 2/50; 12/50; ARF_id177+CDK4_id60.\n",
      "Computing ... 2/50; 13/50; ARF_id177+COX2_id564.\n",
      "Computing ... 2/50; 14/50; ARF_id177+Caspase3_id317.\n",
      "Computing ... 2/50; 15/50; ARF_id177+Caspase9_id343.\n",
      "Computing ... 2/50; 16/50; ARF_id177+E2F_1_id199.\n",
      "Computing ... 2/50; 17/50; ARF_id177+EP4_id610.\n",
      "Computing ... 2/50; 18/50; ARF_id177+EZH2_id535.\n",
      "Computing ... 2/50; 19/50; ARF_id177+Elk_1_id661.\n",
      "Computing ... 2/50; 20/50; ARF_id177+ErbB1_id298.\n",
      "Computing ... 2/50; 21/50; ARF_id177+Erk_id36.\n",
      "Computing ... 2/50; 22/50; ARF_id177+Ets_2_id38.\n"
     ]
    }
   ],
   "source": [
    "# Here, we compute the perturbation results for all model types.\n",
    "# Note that this process can take several hours, as the number\n",
    "# of interventions is very high.\n",
    "\n",
    "intervention_results = {}\n",
    "with open('dual-perturbation.tsv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter='\\t')\n",
    "    \n",
    "    header = [\"Intervention\", \"Model\"] + variables\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for i in range(len(DRUGGABLE)):\n",
    "        for j in range(len(DRUGGABLE)):\n",
    "            if j <= i:\n",
    "                # Only test unique combinations\n",
    "                continue\n",
    "            intervention = f\"{DRUGGABLE[i]}+{DRUGGABLE[j]}\"\n",
    "            intervention_results[intervention] = {}\n",
    "            \n",
    "            print(f\"Computing ... {i+1}/{len(DRUGGABLE)}; {j+1}/{len(DRUGGABLE)}; {intervention}.\")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            # Compute and save trap space of the wildtype model.\n",
    "            wt_pn = petri_nets['healthy'].knockout(DRUGGABLE[i]).knockout(DRUGGABLE[j])\n",
    "            wt_trap = trapmvn(wt_pn, None)\n",
    "            assert len(wt_trap) == 1\n",
    "            wt_trap = wt_trap[0]\n",
    "            intervention_results[intervention]['healthy'] = wt_trap\n",
    "            row = [intervention, 'healthy'] + [ str(wt_trap[x]) for x in variables ]\n",
    "            writer.writerow(row)\n",
    "            csvfile.flush()\n",
    "            \n",
    "            # If a wildtype model has worst-case `Apoptosis` value more\n",
    "            # than three, we skip to the next intervention.\n",
    "            if wt_trap['Apoptosis_id316'][-1] >= 3:\n",
    "                print(f\"Skipped as non-viable.\")\n",
    "                continue\n",
    "            \n",
    "            # Otherwise, we compute the results for the remaining two models. \n",
    "            for model_type in [\"mixed-myc-low\", \"mixed-myc-high\"]:\n",
    "                pn = petri_nets[model_type].knockout(DRUGGABLE[i]).knockout(DRUGGABLE[j])\n",
    "                trap = trapmvn(pn, None)\n",
    "                assert len(trap) == 1\n",
    "                trap = trap[0]\n",
    "                intervention_results[intervention][model_type] = trap\n",
    "                row = [intervention, model_type] + [ str(trap[x]) for x in variables ]\n",
    "                writer.writerow(row)\n",
    "                csvfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84128e13-201d-44f1-bff5-6e3acf49b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we can just load the results from \n",
    "# a file that we saved before.\n",
    "\n",
    "intervention_results = {}\n",
    "with open('dual-perturbation.tsv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    next(reader) # Skip header\n",
    "    for row in reader:\n",
    "        intervention = row[0]\n",
    "        model_type = row[1]\n",
    "        trap = { var: eval(row[i+2]) for i, var in enumerate(variables) }\n",
    "        if intervention not in intervention_results:\n",
    "            intervention_results[intervention] = {}\n",
    "        intervention_results[intervention][model_type] = trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bce4ce6-8eec-4567-86ae-a8c424d342ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering: 1040\n",
      "After filtering: 995\n"
     ]
    }
   ],
   "source": [
    "# Now we can filter out interventions which are not\n",
    "# viable due to high apoptosis values:\n",
    "\n",
    "print(f\"Before filtering: {len(intervention_results)}\")\n",
    "interventions = list(intervention_results.keys())\n",
    "for intervention in interventions:\n",
    "    if len(intervention_results[intervention]) == 1:\n",
    "        del intervention_results[intervention]\n",
    "    # We \"skip\" the myc-related interventions because\n",
    "    # it is not clear how they are implemented across\n",
    "    # different model variants.\n",
    "    if \"Myc\" in intervention:\n",
    "        del intervention_results[intervention]\n",
    "print(f\"After filtering: {len(intervention_results)}\")\n",
    "interventions = list(intervention_results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "407eeeef-33b1-46d4-b184-6a378e6b523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can compute the reliability and opportunity\n",
    "# scores for all perturbations:\n",
    "opportunity = {}\n",
    "reliability = {}\n",
    "\n",
    "for intervention in interventions:\n",
    "    x = intervention_results[intervention]\n",
    "    a_score = x['mixed-myc-low']['Apoptosis_id316'][-1] + x['mixed-myc-high']['Apoptosis_id316'][-1]\n",
    "    p_score = x['mixed-myc-low']['Proliferation_id47'][0] + x['mixed-myc-high']['Proliferation_id47'][0]\n",
    "    opportunity[intervention] = a_score - p_score\n",
    "    \n",
    "    a_score = x['mixed-myc-low']['Apoptosis_id316'][0] + x['mixed-myc-high']['Apoptosis_id316'][0]\n",
    "    p_score = x['mixed-myc-low']['Proliferation_id47'][-1] + x['mixed-myc-high']['Proliferation_id47'][-1]\n",
    "    reliability[intervention] = a_score - p_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31093692-b483-4e48-995a-91ea22c4419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then sort the interventions by the average of the two\n",
    "# scores and output the result to a file.\n",
    "\n",
    "sorted_interventions = sorted(interventions, key=lambda x: -(opportunity[x] + reliability[x])/2)\n",
    "with open('sorted-dual-perturbation.tsv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter='\\t')\n",
    "    \n",
    "    header = [\"Intervention\", \"Reliability\", \"Opportunity\"]\n",
    "    header += [\"Apoptosis (WT)\", \"Apoptosis (mixed-myc-low)\", \"Apoptosis (mixed-myc-high)\"]\n",
    "    header += [\"Proliferation (mixed-myc-low)\", \"Proliferation (mixed-myc-high)\"]\n",
    "    writer.writerow(header)\n",
    "    for i in sorted_interventions:    \n",
    "        row = [i, reliability[i], opportunity[i]]\n",
    "        row += [intervention_results[i][m]['Apoptosis_id316'] for m in ['healthy', 'mixed-myc-low', 'mixed-myc-high']]\n",
    "        row += [intervention_results[i][m]['Proliferation_id47'] for m in ['mixed-myc-low', 'mixed-myc-high']]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b06eddc-737d-491f-ae5d-11a3bf6c5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we are interested in the distribution of \n",
    "# score differences.\n",
    "\n",
    "differences = {}\n",
    "for i in sorted_interventions:\n",
    "    diff = opportunity[i] - reliability[i]\n",
    "    if diff not in differences:\n",
    "        differences[diff] = 0\n",
    "    differences[diff] += 1\n",
    "    \n",
    "differences_histogram = [(k, differences[k]) for k in sorted(differences.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bbfed566-75d6-430a-a9c1-24c3d40314d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 439),\n",
       " (1, 17),\n",
       " (2, 76),\n",
       " (3, 160),\n",
       " (4, 69),\n",
       " (5, 57),\n",
       " (6, 45),\n",
       " (7, 29),\n",
       " (8, 49),\n",
       " (9, 48),\n",
       " (10, 4),\n",
       " (11, 2)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differences_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb8768e-20c6-4ba1-88db-c98c96bc87de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
